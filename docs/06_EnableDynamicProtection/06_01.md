---
title: '01: Create IRM “Risky AI usage” policy and align Communication Compliance'
layout: default
nav_order: 1
parent: 'Exercise 06: Enable dynamic protections'
---

 
## Task 01: Create IRM “Risky AI usage” policy and align Communication Compliance

1. [] In the left menu, select **Solutions**, then **Insider Risk Management**, and then **Policies**.

1. [] Check the policy titled **DSPM for AI – Detect risky AI usage**.

1. [] Select **Edit policy**.

1. [] Leave all settings unchanged and select **Next** until the **Triggering event** step.

    <!--We might need to move the step below to a different task-->

1. [] Check **Risky or sensitive content in Microsoft Copilot experiences, Enterprise AI apps and web versions of other AI apps**.


1. [] Select **Chose your own thresholds**.


    {: .note }
    > We recommend that you use a low threshold when setting up your demo environment, so it is easy to trigger the policy for a demo. In a real customer situation, start by selecting **Apply thresholds provided by Microsoft** and adjust as needed based on the volume of alerts.

1. [] Change the values to **1** per day on both fields and then select **Next**.

    {: .note }
    > In a real environment, you could also change the thresholds for Microsoft Copilot experiences in the **Generative AI apps** section. The same values would be reccomended (>0 to 10 events for low severity, 1 to 50 for medium and 2 > 50 for high severity events)

1. [] On the **Indicator thresholds** step, select **Sequence detection**. 

    {: .note }
    > On the **Choose threshold type** for indicators page, in a real customer situation, you’d start with **Apply thresholds provided by Microsoft** and adjust as needed based on the volume of alerts. 
   
1. [] Change all indicators, from the top to the bottom to:

    - 0 = low, 
    - 1 = medium, 
    - 2 = high. 
    
1. [] You'll keep Risk score booster to its default values and select **Next**.

1.  [] Make sure all boxes on the **Detection options** page are selected, then select **Next**.
    
1. [] Select **Submit** and then **Done**. 

    <!-- This might be moved to a separate task -----------
    ---------------------------------------------------------->


1. [] In the left navigation menu, select **Solutions**, then **Communication Compliance**.

1. [] Select **Policies**. 

1. [] Check the box next to the policy you just created, which will be titled **Insider Risk trigger 25-08-05T21.1628z**, then select the **Edit** icon (the pencil). 

1. [] Select **Next** three times. 

1. [] On the **Choose locations to detect communications** page, check the box for **Microsoft Copilot experiences** and then select **Next**. 

<!--removed as the step is not necessary

    1. [] In the **Conditions** section, under **Content matches any of these trainable classifiers**, select the **Delete** (trash can) icon to the right of **Threat** and then **Targeted harassment**.
    -->

1. [] Select **Add**, then **Trainable classifiers**. 

1. [] Scroll down and select **Prompt shields** and **Protected materials**. 

   {: .note }
   > These classifiers are marked as premium. There is no additional charge for using these classifiers to analyze the interactions of Microsoft 365 Copilot or Copilot Studio agents published to a Microsoft channel. 
   
1. [] Select **Add**, then select select **Add condition**, and **Content contains any of these sensitive info types**. 

1. [] Type group name: **`SITs`**. 

1. [] Select **Add** again and then select **Sensitive info types**. 

1. [] Type to search for **`Credit Card Number`**. 

1. [] Type to search **`Proseware Merger`**, then select **Add**. 

1. [] Select **Next**, then **Save** and **Done**.
